{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1_0B6RXIl_Bz-pC7gMq4iLb0Se_m1Pbuc","authorship_tag":"ABX9TyOxUnt77Rz3z5gB+B7Uhhp4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"50ca7fddd72145f4b99720b32ce7246f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0871019163b944458c1331fed955c0a9","IPY_MODEL_13569f53f6fa4128ba7b28f1ea0cce75","IPY_MODEL_e51148a940f34972b062de14a949c016"],"layout":"IPY_MODEL_2c4b3895a1824a5d91f60c752a5bfce7"}},"0871019163b944458c1331fed955c0a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffe6b99b3ff845ee94ea35ae244661cf","placeholder":"​","style":"IPY_MODEL_2cc41210707541c3a2fa7d787e9d7c57","value":"Downloading (…)ve/main/spiece.model: 100%"}},"13569f53f6fa4128ba7b28f1ea0cce75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_621a149750a44c469bbdab31dbe3008f","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12fc80751a6246a582911e011e1889bb","value":798011}},"e51148a940f34972b062de14a949c016":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a2ca10ddfe64fd8b3a2f8a012428e2e","placeholder":"​","style":"IPY_MODEL_dd0675d81c0d4434b421dcd2696a4e89","value":" 798k/798k [00:00&lt;00:00, 1.09MB/s]"}},"2c4b3895a1824a5d91f60c752a5bfce7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffe6b99b3ff845ee94ea35ae244661cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc41210707541c3a2fa7d787e9d7c57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"621a149750a44c469bbdab31dbe3008f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12fc80751a6246a582911e011e1889bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a2ca10ddfe64fd8b3a2f8a012428e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd0675d81c0d4434b421dcd2696a4e89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de5b5a35e6574883884c55ee7d506128":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d6ca14a5d843f39a5af02fed8dcfde","IPY_MODEL_c6c17fb6f610449d8f514d0b40a6696c","IPY_MODEL_4ae8ed09c2ce45b1a50b1d3800b7506e"],"layout":"IPY_MODEL_c358b7488afc4b688195cecbe24022c6"}},"04d6ca14a5d843f39a5af02fed8dcfde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2a3a3805e2a45b1b76b7dc01fde2699","placeholder":"​","style":"IPY_MODEL_9193791e47f6478a8d553ac8bb6fb8ab","value":"Downloading (…)lve/main/config.json: 100%"}},"c6c17fb6f610449d8f514d0b40a6696c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_129c2cf318064c4686f954447796211c","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75353b0429f54e6f8ecbdc55a69c651a","value":760}},"4ae8ed09c2ce45b1a50b1d3800b7506e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e178803affb47ac81eabacaa8451e27","placeholder":"​","style":"IPY_MODEL_8b1af319412945df8551658999da9bdf","value":" 760/760 [00:00&lt;00:00, 20.2kB/s]"}},"c358b7488afc4b688195cecbe24022c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2a3a3805e2a45b1b76b7dc01fde2699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9193791e47f6478a8d553ac8bb6fb8ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"129c2cf318064c4686f954447796211c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75353b0429f54e6f8ecbdc55a69c651a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e178803affb47ac81eabacaa8451e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1af319412945df8551658999da9bdf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c4161db288849b5adfc0afdccf802f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b426feff93b74ead9f0749a31114344c","IPY_MODEL_818e11906f3046cb97f0299b3af078ca","IPY_MODEL_9bfd74a138984be8ac48c416d136b73c"],"layout":"IPY_MODEL_582cd714d3754f2cafc9a7864f1737b8"}},"b426feff93b74ead9f0749a31114344c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23e42164834a4389b0ac6835d20f480f","placeholder":"​","style":"IPY_MODEL_9a647158484d4a7cb820e190d34fe03a","value":"Downloading pytorch_model.bin: 100%"}},"818e11906f3046cb97f0299b3af078ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_313a0624b808454d865b0e038390fc16","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_856093f3089a42509204a6a458407ba9","value":467042463}},"9bfd74a138984be8ac48c416d136b73c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6285dbcdb8b4a8c84f12617821091a2","placeholder":"​","style":"IPY_MODEL_7fc9d4831256416b982e284eddd84ef5","value":" 467M/467M [00:02&lt;00:00, 176MB/s]"}},"582cd714d3754f2cafc9a7864f1737b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23e42164834a4389b0ac6835d20f480f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a647158484d4a7cb820e190d34fe03a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"313a0624b808454d865b0e038390fc16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"856093f3089a42509204a6a458407ba9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6285dbcdb8b4a8c84f12617821091a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fc9d4831256416b982e284eddd84ef5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUuwObTWRn9Z","executionInfo":{"status":"ok","timestamp":1695403553516,"user_tz":-420,"elapsed":21502,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"f95e7ec0-8cd9-48f7-f81d-921009280c38"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"]}]},{"cell_type":"code","source":["!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQwnaVIQSQkV","executionInfo":{"status":"ok","timestamp":1695403559261,"user_tz":-420,"elapsed":5750,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"2f793315-7e7a-4f8b-9c52-35a61cb50909"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XO1FCScoGUx1","executionInfo":{"status":"ok","timestamp":1695403565218,"user_tz":-420,"elapsed":5962,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"3196f882-0414-44e1-cbe8-9c454fa99503"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["import transformers\n","from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n","import torch\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from collections import defaultdict\n","from textwrap import wrap\n","from pylab import rcParams\n","\n","from torch import nn, optim\n","from keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F"],"metadata":{"id":"LDvIAXQIDscj","executionInfo":{"status":"ok","timestamp":1695403575326,"user_tz":-420,"elapsed":10113,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from sklearn.utils import shuffle\n","import re\n","# Reading data using pandas\n","path_to_data = \"/content/drive/MyDrive/GRAD/2023-HK2/AdvancedERP/Data/IMDB Dataset.csv\"\n","df = pd.read_csv(path_to_data)\n","\n","# Shuffle and Clip data\n","df = shuffle(df)\n","df = df[:24000]\n","\n","# Function to clean text. Remove tagged entities, hyperlinks, emojis\n","def clean_text(text):\n","    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n","    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n","    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n","    text = re.sub('\\t', ' ',  text)\n","    text = re.sub(r\" +\", ' ', text)\n","    return text\n","\n","df['review'] = df['review'].apply(clean_text)\n","\n","# Function to convert labels to number.\n","def sentiment2label(sentiment):\n","    if sentiment == \"positive\":\n","        return 1\n","    else :\n","        return 0\n","\n","df['sentiment'] = df['sentiment'].apply(sentiment2label)\n","\n","# List of class names.\n","class_names = ['negative', 'positive']"],"metadata":{"id":"phn7JKX3Eca2","executionInfo":{"status":"ok","timestamp":1695403587913,"user_tz":-420,"elapsed":12594,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from transformers import XLNetTokenizer\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n","input_txt = \"Text data\"\n","encodings = tokenizer.encode_plus(input_txt, add_special_tokens=True, max_length=16, return_tensors='pt', return_token_type_ids=False, return_attention_mask=True, pad_to_max_length=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["50ca7fddd72145f4b99720b32ce7246f","0871019163b944458c1331fed955c0a9","13569f53f6fa4128ba7b28f1ea0cce75","e51148a940f34972b062de14a949c016","2c4b3895a1824a5d91f60c752a5bfce7","ffe6b99b3ff845ee94ea35ae244661cf","2cc41210707541c3a2fa7d787e9d7c57","621a149750a44c469bbdab31dbe3008f","12fc80751a6246a582911e011e1889bb","7a2ca10ddfe64fd8b3a2f8a012428e2e","dd0675d81c0d4434b421dcd2696a4e89","de5b5a35e6574883884c55ee7d506128","04d6ca14a5d843f39a5af02fed8dcfde","c6c17fb6f610449d8f514d0b40a6696c","4ae8ed09c2ce45b1a50b1d3800b7506e","c358b7488afc4b688195cecbe24022c6","d2a3a3805e2a45b1b76b7dc01fde2699","9193791e47f6478a8d553ac8bb6fb8ab","129c2cf318064c4686f954447796211c","75353b0429f54e6f8ecbdc55a69c651a","5e178803affb47ac81eabacaa8451e27","8b1af319412945df8551658999da9bdf"]},"id":"iyvJmxCNGnPF","executionInfo":{"status":"ok","timestamp":1695403591704,"user_tz":-420,"elapsed":3795,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"1cb83e09-d2da-4c5a-d49d-50c82c8f31fc"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50ca7fddd72145f4b99720b32ce7246f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de5b5a35e6574883884c55ee7d506128"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["class ImdbDataset(Dataset):\n","\n","    def __init__(self, reviews, targets, tokenizer, max_len):\n","        self.reviews = reviews\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.reviews)\n","\n","    def __getitem__(self, item):\n","        review = str(self.reviews[item])\n","        target = self.targets[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","        review,\n","        add_special_tokens=True,\n","        max_length=self.max_len,\n","        return_token_type_ids=False,\n","        pad_to_max_length=False,\n","        return_attention_mask=True,\n","        return_tensors='pt',\n","        )\n","\n","        input_ids = pad_sequences(encoding['input_ids'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n","        input_ids = input_ids.astype(dtype = 'int64')\n","        input_ids = torch.tensor(input_ids)\n","\n","        attention_mask = pad_sequences(encoding['attention_mask'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n","        attention_mask = attention_mask.astype(dtype = 'int64')\n","        attention_mask = torch.tensor(attention_mask)\n","\n","        return {\n","        'review_text': review,\n","        'input_ids': input_ids,\n","        'attention_mask': attention_mask.flatten(),\n","        'targets': torch.tensor(target, dtype=torch.long)\n","        }"],"metadata":{"id":"dlas1pqaGvO7","executionInfo":{"status":"ok","timestamp":1695403591704,"user_tz":-420,"elapsed":18,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def create_data_loader(df, tokenizer, max_len, batch_size):\n","  ds = ImdbDataset(\n","    reviews=df.review.to_numpy(),\n","    targets=df.sentiment.to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4\n","  )"],"metadata":{"id":"Ciln7EBQHKb1","executionInfo":{"status":"ok","timestamp":1695403591705,"user_tz":-420,"elapsed":16,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","df_train, df_val = train_test_split(df, test_size=0.2) # train 80 - val 20\n","df_test, df_val = train_test_split(df_val, test_size=0.5) # val 10 - test 10"],"metadata":{"id":"vUCWhSaqHfVs","executionInfo":{"status":"ok","timestamp":1695403591705,"user_tz":-420,"elapsed":15,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df_train.shape, df_val.shape, df_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9nKSztqKv6C","executionInfo":{"status":"ok","timestamp":1695403591706,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"0f42d72e-48b2-4047-c0e0-2cfc5a730fe1"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((19200, 2), (2400, 2), (2400, 2))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["BATCH_SIZE = 4\n","MAX_LEN=512\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"],"metadata":{"id":"9kQ9JSvxHSEB","executionInfo":{"status":"ok","timestamp":1695403591706,"user_tz":-420,"elapsed":10,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4db592d4-3ef9-4d01-d51a-66df6725ea35"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["from transformers import XLNetForSequenceClassification\n","\n","device = 'cuda'\n","model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2)\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["3c4161db288849b5adfc0afdccf802f8","b426feff93b74ead9f0749a31114344c","818e11906f3046cb97f0299b3af078ca","9bfd74a138984be8ac48c416d136b73c","582cd714d3754f2cafc9a7864f1737b8","23e42164834a4389b0ac6835d20f480f","9a647158484d4a7cb820e190d34fe03a","313a0624b808454d865b0e038390fc16","856093f3089a42509204a6a458407ba9","b6285dbcdb8b4a8c84f12617821091a2","7fc9d4831256416b982e284eddd84ef5"]},"id":"fEkapDf_L6QZ","executionInfo":{"status":"ok","timestamp":1695403599779,"user_tz":-420,"elapsed":8081,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"e992236b-0fcc-4ac4-a4a2-d20b82233b86"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c4161db288849b5adfc0afdccf802f8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["EPOCHS = 3\n","BATCH_SIZE = 4\n","\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","                                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n","\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")"],"metadata":{"id":"K0ZuSuFgKJxz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695403599779,"user_tz":-420,"elapsed":17,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"d2c6fcb6-7365-4ef4-8d94-e801fe586c1a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n","    model = model.train()\n","    losses = []\n","    acc = 0\n","    counter = 0\n","\n","    for d in data_loader:\n","        input_ids = d[\"input_ids\"].reshape(4,512).to(device)\n","        attention_mask = d[\"attention_mask\"].to(device)\n","        targets = d[\"targets\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n","        loss = outputs[0]\n","        logits = outputs[1]\n","\n","        # preds = preds.cpu().detach().numpy()\n","        _, prediction = torch.max(outputs[1], dim=1)\n","        targets = targets.cpu().detach().numpy()\n","        prediction = prediction.cpu().detach().numpy()\n","        accuracy = metrics.accuracy_score(targets, prediction)\n","\n","        acc += accuracy\n","        losses.append(loss.item())\n","\n","        loss.backward()\n","\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        counter = counter + 1\n","\n","    return acc / counter, np.mean(losses)"],"metadata":{"id":"2KqA5L5HLk9e","executionInfo":{"status":"ok","timestamp":1695403599780,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def eval_model(model, data_loader, device, n_examples):\n","    model = model.eval()\n","    losses = []\n","    acc = 0\n","    counter = 0\n","\n","    with torch.no_grad():\n","        for d in data_loader:\n","            input_ids = d[\"input_ids\"].reshape(4,512).to(device)\n","            attention_mask = d[\"attention_mask\"].to(device)\n","            targets = d[\"targets\"].to(device)\n","\n","            outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n","            loss = outputs[0]\n","            logits = outputs[1]\n","\n","            _, prediction = torch.max(outputs[1], dim=1)\n","            targets = targets.cpu().detach().numpy()\n","            prediction = prediction.cpu().detach().numpy()\n","            accuracy = metrics.accuracy_score(targets, prediction)\n","\n","            acc += accuracy\n","            losses.append(loss.item())\n","            counter += 1\n","\n","    return acc / counter, np.mean(losses)"],"metadata":{"id":"oWpraNhzMuW5","executionInfo":{"status":"ok","timestamp":1695403599780,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["%%time\n","history = defaultdict(list)\n","best_accuracy = 0\n","\n","for epoch in range(EPOCHS):\n","    print(f'Epoch {epoch + 1}/{EPOCHS}')\n","    print('-' * 10)\n","\n","    train_acc, train_loss = train_epoch(\n","        model,\n","        train_data_loader,\n","        optimizer,\n","        device,\n","        scheduler,\n","        len(df_train)\n","    )\n","\n","    print(f'Train loss {train_loss} Train accuracy {train_acc}')\n","\n","    val_acc, val_loss = eval_model(\n","        model,\n","        val_data_loader,\n","        device,\n","        len(df_val)\n","    )\n","\n","    print(f'Val loss {val_loss} Val accuracy {val_acc}')\n","    print()\n","\n","    history['train_acc'].append(train_acc)\n","    history['train_loss'].append(train_loss)\n","    history['val_acc'].append(val_acc)\n","    history['val_loss'].append(val_loss)\n","\n","    if val_acc > best_accuracy:\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/GRAD/2023-HK2/AdvancedERP/models/xlnet_model.bin')\n","        best_accuracy = val_acc"],"metadata":{"id":"IW-JA7LGLkny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695415427861,"user_tz":-420,"elapsed":11828093,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"03f1ea16-d106-40d9-a98e-e4139834c381"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","----------\n","Train loss 0.37616366346036256 Train accuracy 0.9133333333333333\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Val loss 0.3112817341690728 Val accuracy 0.9370833333333334\n","\n","Epoch 2/3\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.19523098655073226 Train accuracy 0.9610416666666667\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Val loss 0.33346962436373967 Val accuracy 0.9416666666666667\n","\n","Epoch 3/3\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.08854559538122052 Train accuracy 0.9847395833333333\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Val loss 0.32829403560489784 Val accuracy 0.94875\n","\n","CPU times: user 3h 12min 26s, sys: 1min 43s, total: 3h 14min 9s\n","Wall time: 3h 17min 8s\n"]}]},{"cell_type":"code","source":["test_acc, test_loss = eval_model(\n","  model,\n","  test_data_loader,\n","  device,\n","  len(df_test)\n",")\n","\n","print('Test Accuracy :', test_acc)\n","print('Test Loss :', test_loss)"],"metadata":{"id":"yW_1DzShRCKQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695415664923,"user_tz":-420,"elapsed":237068,"user":{"displayName":"Ngân Nguyễn Đắc Thiên","userId":"01493861674003123391"}},"outputId":"af2b4947-830a-47e6-ca64-f8ae69013c1a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy : 0.94375\n","Test Loss : 0.3598046371585951\n"]}]}]}